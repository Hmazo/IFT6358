---
layout: post
title:  "Milestone 2"
date:   2024-11-21 19:18:08 -0400
categories: Milestones
pin: true
author: "Equipe 10"
by: "Equipe 10"
---



Dans ce blog, nous explorons différentes méthodes de modélisation pour prédire les buts au hockey à partir de données de tirs. L'objectif est d'identifier les modèles les plus performants et de comprendre les caractéristiques les plus influentes dans ce processus. Nous suivons une approche méthodique en commençant par des modèles simples et en ajoutant progressivement des caractéristiques et des techniques avancées, comme l'optimisation des hyperparamètres et la sélection de caractéristiques. 

Pour chaque étape, nous produisons des visualisations et analysons les performances des modèles à l'aide de courbes standard telles que la courbe ROC/AUC, le taux de buts par rapport au percentile de probabilité, la proportion cumulée de buts et la courbe de calibration. Ces analyses visent à fournir un aperçu complet de la capacité prédictive de chaque modèle.

Nous utilisons **Weights & Biases (Wandb)** pour suivre nos expériences et enregistrer nos modèles, ce qui nous permet de documenter efficacement les résultats et de partager les liens vers les expériences avec précision.

---

## Partie 1 : Configuration du projet Wandb

Pour suivre et documenter nos expériences, nous avons configuré un projet dans **Weights & Biases (Wandb)**. Ce projet servira de plateforme centrale pour enregistrer les métriques de performance, les hyperparamètres et les modèles générés à chaque étape.

Chaque expérience est associée à un run dans Wandb. Cela permettra de visualiser les courbes, les métriques, et les modèles enregistrés de manière interactive et accessible.

Vous pouvez explorer tous les run ici : [Lien vers le projet Wandb](https://wandb.ai/hicham-mazouzi-university-of-montreal/IFT6758.2024-A?nw=nwuserhichammazouzi).

---

Dans les prochaines sections, nous décrivons les étapes suivies pour entraîner et comparer les modèles, en fournissant les résultats détaillés et les liens directs vers les expériences associées.


## Partie 2 : Ingénierie des caractéristiques I


### Analyse des caractéristiques : Distance et Angle

#### Distribution des tirs par distance

Le graphique ci-dessous présente la distribution des tirs en fonction de leur distance au filet, en distinguant les tirs réussis (buts) et les tirs manqués. Les tirs manqués (en bleu) constituent une majorité écrasante par rapport aux tirs réussis (en vert), quelle que soit la distance. Cela reflète une réalité bien connue du hockey : la difficulté de marquer un but augmente à mesure que la distance au filet grandit.

![Histogramme Tirs par Distance](images\fe1_histo_tir_par_distance.png)

En observant les barres, on constate que la majorité des tirs sont effectués à une distance relativement courte, généralement entre 10 et 30 pieds. Les tirs à courte distance ont également un pourcentage légèrement plus élevé de succès, bien que les buts restent une minorité même dans cette zone. En revanche, à mesure que la distance augmente, le nombre total de tirs diminue fortement, et les tirs réussis deviennent extrêmement rares au-delà de 50 pieds.

Cette analyse met en évidence l'importance de la proximité du filet pour maximiser les chances de marquer, tout en rappelant que d'autres facteurs comme l'angle, le type de tir et le contexte du jeu influencent également le succès.



#### Distribution des tirs par angle

Le graphique suivant met en lumière l’impact de l’angle des tirs sur leur probabilité de succès. 

![Histogramme Tir par angle](images\fe1_histo_tir_par_angle.png)

Nous observons que les tirs alignés avec l’axe central (autour de 0 degré) sont nettement plus fréquents et présentent une proportion plus élevée de buts. Cela peut être attribué à une meilleure perspective pour le joueur ainsi qu’à une réduction des interférences défensives. À l’inverse, les tirs effectués à des angles extrêmes, bien que rares, affichent des taux de réussite beaucoup plus faibles. Cette observation peut s’expliquer par des perspectives limitées et des opportunités de placement plus complexes.


#### Analyse combinée : Distance et Angle

La visualisation 2D suivante combine les dimensions de la distance et de l’angle pour illustrer la répartition des tirs réussis et ratés en fonction de leur position sur la patinoire.

![Histogramme 2D](images\fe1_histo_2d_angle_distance.png)

Les tirs proches du filet (distances inférieures à 20 pieds) montrent une densité nettement plus élevée de buts, représentés par une concentration de points orange. À mesure que la distance augmente, la proportion de tirs ratés (points bleus) devient prépondérante. Par ailleurs, les tirs réalisés à des angles proches de l'axe central (environ 0 degré) semblent avoir une probabilité de succès plus élevée. Ces résultats confirment que la proximité du filet et un alignement optimal influencent directement les chances de marquer.



#### Taux de réussite des buts par distance et angle

Le graphique suivant explore le taux de réussite des buts en fonction de la distance et de l’angle. 

![Histogramme Taux de but en fonction angle et distance](images\fe1_histo_taux_angle_distance.png)

Concernant la distance, nous constatons une décroissance rapide du taux de réussite : les tirs effectués à moins de 10 pieds affichent un taux exceptionnellement élevé (plus de 25 %), tandis que les tirs réalisés au-delà de 40 pieds présentent des taux de réussite quasi négligeables. Du côté des angles, on observe une dynamique oscillante : les tirs proches de l'axe central (0 degré) ont le taux de réussite le plus élevé, suivis de pics secondaires autour de -25 et 25 degrés. À l’inverse, les angles extrêmes (supérieurs à ±75 degrés) montrent les taux les plus faibles.

Ces analyses renforcent l’idée que la proximité et l’alignement avec l’axe central du filet jouent un rôle crucial dans le succès des tirs.



#### Impact des filets vides

Enfin, nous examinons comment la présence ou l'absence d'un gardien influence la répartition des buts. 

![Histogramme Buts par distance](images\fe1_histo_but_distance.png)

Pour les filets vides, les buts sont relativement uniformément répartis quelle que soit la distance, bien que l’on observe un léger pic autour des 20 pieds. Cela montre que l’absence de gardien réduit considérablement l’impact de la distance sur la probabilité de succès. À l’inverse, pour les filets non vides, une forte concentration de buts est observée à des distances inférieures à 20 pieds. Au-delà de cette limite, la probabilité de succès diminue drastiquement, soulignant l’importance de la proximité pour surmonter la défense d’un gardien actif.



#### Conclusion

Ces observations confirment que la distance et l’angle sont des caractéristiques essentielles pour comprendre la probabilité de succès des tirs au hockey. L’analyse met également en lumière l’importance du contexte, comme la présence d’un gardien ou les conditions du tir. Ces résultats guideront la sélection des caractéristiques et le développement de modèles prédictifs performants.

---
## Partie 3 : Modèles de base

Dans cette troisième étape du Milestone, nous considérons les caractéristiques de distance et d'angle produites dans la section précédente afin de mettre en pratique et tester des modèles simples. L’objectif est de tester la performance des modèles de base afin d’avancer de nouveaux modèles, avec d’autres caractéristiques plus avancées.
Pour ce faire nous procédons de la manière suivante :

### 3.1 Question 1 *Évaluation sur l'ensemble de validation*

En utilisant la caractéristique de distance seulement, cette étape consiste à créer une division d'entraînement et de validation et à entraîner un classificateur de régression logistique simple. Autrement dit, un classificateur de régression logistique avec des paramètres complètement par défaut : 
clf = LogisticRegression()
clf.fit(X, y)

Évaluation de la précision du modèle sur l'ensemble de validation :  

Les résultats de ce premier modèle mettent en lumière un aspect important de nos données : 
Les métriques indiquent un problème grave avec votre modèle de régression logistique, probablement dû à un déséquilibre de classe. Bien que la précision soit élevée, à savoir 94,87 %, la précision, le rappel et le score F1 sont de 0,0, ce qui suggère que le modèle n'a pas réussi à faire de prédictions positives. L’une des explications pourrait découlée de l’existence d'une dépendance excessive à la prédiction de la classe majoritaire, due au déséquilibre de nos données (classes déséquilibrées). Bien que la précision soit élevée, elle est trompeuse, car elle reflète des prédictions correctes pour la classe majoritaire, et donc dominante seulement, mais pas pour l’autre classe qui s’avère être minoritaire. On se retrouve donc avec des résultats qui affirme que la caractéristique ‘distance’ est incapable de différencier les 2 classes en raison d’un biais des données à l’échelle de la classe regroupé par (‘is_goal=0’)

### 3.2 Questions 2 et 3 - *figures*

**Figure 1 : Les courbes Receiver Operating Characteristic (ROC)**

![Courbes ROC des modèles de base](images\roc_base.png)

L’objectif de cette partie était de générer les courbes ROC de 3 modèles de classification par régression logistique, en considérant la distance, l’angle ainsi que la distance t l’angle ensemble. Comme base de comparaison, nous considérons une ligne de base aléatoire. On se retrouve finalement avec 4 modèles. Les valeurs AUC indiquent que les modèles de classification par régression logistique, fondés sur la distance et la distance et l’angle sont plus ou moins similaires et surperforment le modèle basé sur l’angle seulement. De même, les résultats de ce dernier (modèle logistique basé sur l’angle seulement) sont plus ou moins rapprochés a ceux de la ligne de base aléatoire.

**Figure 2 : Taux de buts comme une fonction du centile de la probabilité de tir du modèle** 

![taux de buts comme une fonction du centile de la probabilité de tir donnée par le modèle de base](images\taux_de_but_base.png)

Le deuxième graphique représente le taux de buts réussis et ratés comme une fonction du centile de la probabilité de tir donnée par le modèle. Les courbes démontrent que pour les deux modèles ‘distance’ et ‘distance et angle’, les courbes sont croissantes, indiquant que les probabilités prédites correspondent bien aux taux de buts observés. Cela signifie que, contrairement au modèle 2, les modèles 1 et 3 sont capables de distinguer avec précision les tirs les plus susceptibles de se transformer en buts.

**Figure 3: Proportion cumulée de buts comme une fonction du centile de la probabilité de tir du modèle**

![Proportion cumulative de buts des modèles de base](images\cumulative_base.png)

Le graphique du taux de réussite des buts en fonction du centile de la probabilité de tir nous a permis d'identifier les zones de performance des modèles étudiés et d'évaluer leur précision. Les courbes des modèles 1 et 3 suivent une tendance croissante avec l'augmentation des centiles, ce qui signifie que ces modèles ont une bonne capacité de discrimination par rapport au modèle 2 qui possède une courbe non croissante qui se rapproche de la “ligne de base aléatoire”.

**Figure 4 : Diagramme de fiabilité** 

![Calibration (Courbe de fiabilité) modèles de base](images\calibration_base.png)

Le diagramme de fiabilité nous permet d’élucider à quel degré les probabilités prédites correspondent aux taux réels de réussite. Pour nos modèles, on remarque que ceux-ci ne dévient pas par rapport à la diagonale, c’est-à-dire qu’ils sont bien calibrés. Toutefois, ceci n’est pas le cas pour la ligne de base aléatoire où est ce qu’on remarque que ce modèle tend à sous-estimer les probabilités, du fait que la courbe est située au-dessous de la diagonale. 


---
## Partie 4 : Ajout de nouvelles caractéristiques liés aux évènements précédents

Dans cette partie, nous avons considéré de nouvelles caractéristiques, liés surtout aux évènements précédents. Nous considérons alors les caractéristiques suivantes :
- Game seconds : les secondes de jeu 
- Game period : la periode de jeu
- Les coorodnnées x et y
- Shot distance : la distance à laquelle le tir a été effectué
- Shot angle : l'angle du tir efectué par rapport au filet
- Last event type : le type de l'évènement précédent
- Les coordonnées de cet évènement précédent
- Le temps écoulé depuis le dernier évènement
- La distance effectuée depuis le dernier évènement
- Rebound : booléen qui renvoie Vrai si l'évnement précédent était un shot on goal, Faux sinon
- Angle change : le changement d'angle entre l'évènement et le précédent 
- Speed : La vitesse, définie comme la distance depuis l'événement précédent, divisée par le temps écoulé depuis l'événement précédent. 

Ces caractéristiques vont nous permettre de définir si un tir est bel et bien un rebond. On ne peut pas considérer qu'un tir est un rebond si, par exemple,
c'est le premier tir d'une période. 
Nous avons aussi décidé de fixer une limite temporelle entre deux tirs afin d'épurer notre appellation "rebond". Cette limite temporelle est de *** secondes.
Avec toutes ces nouvelles caractéristiques, nous pouvons alors donner un peu plus de contexte sur chacun des tirs.

---
### Exemple de match : Winnipeg versus Washington

Nous avons isolé un match en particulier : un match entre les Winnipeg Jets et les Washington Capitals. Pour ce match, nous avons créé une expérience sur wandb, en voici le lien : https://wandb.ai/hicham-mazouzi-university-of-montreal/IFT6758.2024-A/artifacts/dataset/wpg_v_wsh_2017021065

---
## Partie 5 : Modèles avancés

### Partie 5.1 : Baseline XGBoost (Distance et Angle)

Dans cette première étape, nous avons entraîné un modèle **XGBoost baseline** en utilisant uniquement les caractéristiques `shot_distance` et `shot_angle`. L’objectif était de comparer ses performances avec celles du modèle de **régression logistique de référence** présenté dans la partie 3.

Pour cela, nous avons créé une copie du jeu de données contenant uniquement les colonnes suivantes :
- `shot_distance` : la distance à laquelle le tir a été effectué
- `shot_angle` : l’angle du tir effectué par rapport au filet
- `is_goal` : notre variable cible

Le modèle XGBoost baseline a obtenu une **AUC de 0.715**, ce qui représente une amélioration notable par rapport à la régression logistique de référence, dont l’AUC était de 0.691. Cette différence met en évidence la capacité de XGBoost à capturer des relations complexes, même avec des caractéristiques limitées et sans réglage des hyperparamètres.

#### Visualisations
Voici les courbes associées à ce modèle baseline :
- **ROC/AUC**
  ![ROC Baseline XGBoost](images\roc_5_1.png)

- **Taux de buts vs percentile de probabilité**
  ![Taux de Buts Baseline XGBoost](images\goal_rate_5_1.png)

- **Proportion cumulée de buts vs percentile de probabilité**
  ![Proportion Cumulée Baseline XGBoost](images\cumulative_goals__5_1.png)

- **Courbe de calibration**
  ![Calibration Baseline XGBoost](images\calibration_5_1.png)

---

### Partie 5.2 : XGBoost avec toutes les caractéristiques

Dans cette étape, nous avons utilisé **l’ensemble complet des caractéristiques créées dans la partie 4** pour entraîner un modèle XGBoost. Avant de commencer l'entraînement, nous avons normalisé les données afin d'assurer une échelle cohérente entre les différentes caractéristiques, ce qui est particulièrement utile pour améliorer la stabilité des modèles complexes.

Nous avons ensuite effectué une recherche d’hyperparamètres en utilisant une validation croisée. Les hyperparamètres testés sont les suivants :

```python
param_grid = {
    'n_estimators': [150, 200, 250, 300],
    'learning_rate': [0.01, 0.1, 0.15, 0.015],
    'max_depth': [7, 10, 15],
    'subsample': [0.9, 0.7, 1.0]
}
```
Après une exploration exhaustive de ces combinaisons, les meilleurs hyperparamètres trouvés sont :
```python
Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150, 'subsample': 1.0}
```
Avec cet enrichissement des données et l’optimisation des hyperparamètres, le modèle XGBoost a atteint une AUC de 0.783, une amélioration significative par rapport au modèle baseline (0.715). Ce gain confirme l’importance des nouvelles caractéristiques et du réglage précis des hyperparamètres pour maximiser les performances du modèle.

#### Visualisations
Les courbes associées à ce modèle optimisé sont les suivantes :
- **ROC/AUC**
  ![ROC XGBoost Optimisé](images\roc_5_2.png)

- **Taux de buts vs percentile de probabilité**
  ![Taux de Buts XGBoost Optimisé](images\goal_rate_5_2.png)

- **Proportion cumulée de buts vs percentile de probabilité**
  ![Proportion Cumulée XGBoost Optimisé](images\cumulative_goals_5_2.png)

- **Courbe de calibration**
  ![Calibration XGBoost Optimisé](images\calibration_5_2.png)

---

### Partie 5.3 : Sélection de caractéristiques avec RFE

Dans cette partie, nous avons exploré trois techniques différentes de sélection de caractéristiques pour réduire la complexité du modèle tout en maintenant des performances élevées. Les techniques évaluées sont :

1. **SelectKBest** : Cette méthode sélectionne les caractéristiques les plus importantes en se basant sur une métrique statistique comme la corrélation ou le chi-carré.
2. **SHAP (SHapley Additive exPlanations)** : Cette technique attribue une importance aux caractéristiques en fonction de leur contribution aux prédictions du modèle.
3. **RFE (Recursive Feature Elimination)** : Cette méthode élimine itérativement les caractéristiques les moins pertinentes, en utilisant les performances du modèle pour identifier un sous-ensemble optimal.

Parmi les trois techniques de sélection de caractéristiques explorées, RFE s’est démarquée avec une AUC de 0.783 et une précision de 93.1%, égalant les performances du modèle complet tout en simplifiant sa structure. SHAP a obtenu une AUC légèrement inférieure de 0.768 et une précision de 93.0%, offrant un bon équilibre entre réduction et performance. En revanche, SelectKBest a montré les résultats les plus faibles, avec une AUC de 0.757 et une précision de 93.0%, suggérant qu’elle n’identifie pas aussi efficacement les caractéristiques essentielles.

Comparé au XGBoost de la partie 2 (AUC de 0.783), le modèle basé sur RFE atteint la même AUC de 0.783, mais avec un modèle simplifié grâce à l'élimination des caractéristiques redondantes. Cette réduction de complexité offre un avantage en termes d'efficacité et d'interprétabilité, tout en conservant des performances identiques.

#### Visualisations
Les courbes générées pour le modèle basé sur RFE sont les suivantes :
- **ROC/AUC**
  ![ROC XGBoost RFE](images\roc_5_3.png)

- **Taux de buts vs percentile de probabilité**
  ![Taux de Buts XGBoost RFE](images\goal_rate_5_3.png)

- **Proportion cumulée de buts vs percentile de probabilité**
  ![Proportion Cumulée XGBoost RFE](images\cumulative_goals__5_3.png)

- **Courbe de calibration**
  ![Calibration XGBoost RFE](images\calibration_5_3.png)

---

### Conclusion

Les résultats obtenus mettent en lumière l’efficacité des modèles XGBoost dans la prédiction des buts au hockey :
1. Le **baseline XGBoost (distance et angle)** surpasse la régression logistique de référence (AUC : 0.715 vs 0.691).
2. L’ajout de nouvelles caractéristiques et le réglage des hyperparamètres permettent d’atteindre une **AUC de 0.783**.
3. La technique RFE permet de simplifier le modèle sans perte de performance, conservant une **AUC de 0.783** tout en réduisant les dimensions du jeu de données.

Ces résultats confirment que l’utilisation de techniques avancées, comme l’optimisation des hyperparamètres et la sélection de caractéristiques, contribue à la construction de modèles robustes et interprétables. Les expériences associées et leurs visualisations sont accessibles dans [Wandb](https://wandb.ai/hicham-mazouzi-university-of-montreal/IFT6758.2024-A?nw=nwuserhichammazouzi).


# 6. Tentatives de plusieurs modèles

Dans cette section, nous explorons une variété de modèles. Bien entendu, l’objectif n’étant pas de proposer un modèle idéal et optimisé en fonction de nos données, nous nous efforçons à tester plusieurs modèles afin de d’explorer les divers apports de chacun, ainsi que ses failles. 

**Arbre de décision**

Pour ce faire, nous commençons par un arbre de décision, ou est-ce qu’une recherche aléatoire (‘RandomizedSearchCV’) fut favorisée afin d’optimiser les hyperparamètres du modèle. Par la suite, en raison du déséquilibre des classes, nous optons pour SMOTE afin de contrer le déséquilibre de nos données. 

La mise en parallèle du premier modèle et celui utilisant SMOTE met en évidence l'impact du traitement du déséquilibre de classes. Bien que le modèle initial (optimisation des hyperparamètres) atteint une ‘accuracy’ de 94,75 % et une précision de 47,93 %, celui-ci ne permet pas d’identifier efficacement la classe minoritaire, avec un rappel de seulement 2,51 % et un F1-score de 4,77 %. 
Après l'application de SMOTE, l'exactitude diminue à 80,21 %, reflétant le changement du modèle, en raison d’une prise en considération de la classe minoritaire. Le rappel s'est considérablement amélioré, passant de 2,51% à 47,20 %, ce qui indique que le modèle identifie désormais beaucoup plus de vrais positifs. 
Toutefois, la précision a diminué à 12,83 %, et avec un F1-score plus bas de 20,17 %, nous concluons l’existence d’un compromis entre la précision et le rappel. Autrement dit, bien que les résultats démontrent que SMOTE améliore la capacité du modèle à détecter la classe minoritaire, ceci est atteint au détriment de la précision (tradeoff précision/rappel). 
Les 4 figures générées pour les modèles de base furent de même générées pour l'arbre de décision: 

**Figure 1 : Les 4 figures d'évaluations tel que définit auparavant**
![Courbes ROC de l'arbre de décision](images\roc_tree.png)
![taux de buts comme une fonction du centile de la probabilité de tir donnée par l'arbre de décision](images\taux_de_but_tree.png)
![Proportion cumulative de buts de l'arbre de décision](images\cumulative_tree.png)
![Calibration (Courbe de fiabilité) arbre de décision](images\calibration_tree.png)

**LightGBM**
Dans la même trajetoire, nous avons considérons "LightGBM", un modèle performant pour les grands ensembles de données , en raison des caractéristiques du 'Gradient-Based One-Side Sampling' et du 'Exclusive Feature Bundling', optimisant vitesse et mémoire. Le modèle s'adapte bien aux données déséquilibrées, ce qui est le cas de nos données. 
Dans ca cadre, nous avons opté pour Dla stratégie de sélection de caractéristiques suivante : lgb.plot_importance(clf, importance_type="gain")
Cette stratégie nous permet de définir l'importance des caractéristiques en les évaluant en terme de gain moyen lorsque chaque caractérsitique est incluse dans les arbres de décision.
D'après les résultats, avec une 'accuracy' de 0.9498, une précision de 0,6392 et un score auc de 0.8388, ces score reflètent une capacité de discrimination efficace (toujours avec une marge d'amélioration)
Voici les 4 figures d'évaluation tel que les autres modèles:

**Figure 2 : Les 4 figures d'évaluations tel que définit auparavant**
![Courbes ROC de LightGBM](images\roc_lightgbm.png)
![taux de buts comme une fonction du centile de la probabilité de tir donnée par LightGBM](images\taux_de_but_lightgbm.png)
![Proportion cumulative de buts de LightGBM](images\cumulative_lightgbm.png)
![Calibration (Courbe de fiabilité) LightGBM](images\calibration_lightgbm.png)

**TabNet**

TabNet est un modèle de deep learning spécifiquement conçu pour traiter des données tabulaires. Sa structure unique intègre des mécanismes d’interprétabilité avancés tout en permettant une gestion efficace des données déséquilibrées. Pour entraîner notre modèle TabNet, nous avons utilisé les hyperparamètres suivants : un taux d’apprentissage initial de 0.02, une réduction du taux d’apprentissage tous les 10 epochs d’un facteur de 0.9 via un scheduler, et une régularisation basée sur le masque `sparsemax`. De plus, nous avons évalué le modèle sur les métriques AUC, précision et logloss tout au long de l’entraînement.

Les résultats obtenus pour TabNet sont prometteurs, avec une **AUC de 0.833** et une **précision de 93.1%**, plaçant ce modèle parmi les plus performants testés dans cette section. Voici les figures générées pour ce modèle :

**Figure 3 : Les 4 figures d'évaluations pour TabNet**
![Courbes ROC de TabNet](images\roc_tabnet.png)
![Taux de buts comme une fonction du centile de la probabilité de tir donnée par TabNet](images\goal_rate_tabnet.png)
![Proportion cumulative de buts de TabNet](images\cumulative_goals_tabnet.png)
![Calibration (Courbe de fiabilité) TabNet](images\calibration_tabnet.png)

### Conclusion 

Au terme de cette section, plusieurs modèles ont été explorés pour évaluer leur efficacité dans la prédiction des buts. Chaque approche a apporté des perspectives uniques, tant sur le plan des performances que sur celui des méthodes utilisées. 

Parmi les modèles testés :
- **TabNet** a offert des résultats solides, avec une **AUC de 0.833** et une précision de **93.1%**, tout en proposant des mécanismes d’interprétabilité avancés adaptés aux données tabulaires.
- **LightGBM** s'est démarqué comme le modèle le plus performant, avec une **AUC de 0.838** et une précision de **94.98%**, combinant rapidité et efficacité, en particulier grâce à ses techniques d’échantillonnage et de bundling de caractéristiques.
- D'autres modèles, comme l'arbre de décision avec SMOTE, ont mis en lumière l'importance de la gestion des classes déséquilibrées pour améliorer la détection des vrais positifs.

En conclusion,**LightGBM se révèle être la meilleure solution pour cette tâche spécifique**, en raison de ses performances exceptionnelles et de sa capacité à traiter efficacement de grands ensembles de données tabulaires tout en s’adaptant à des données déséquilibrées. Cette exploration souligne l'importance d'essayer plusieurs approches pour trouver la solution la mieux adaptée aux spécificités des données et du problème à résoudre.

---
## Étape 7 : Évaluation des modèles 

Dans cette section, nous avons évalué cinq modèles sur l'ensemble de données de la saison régulière et eliminatoire 2019/20. Les modèles évalués incluent :

1. **Distance Model**
2. **Angle Model**
3. **Combined Model**
4. **XGBoost (meilleur modèle de la Partie 5.2)**
5. **LightGBM (meilleur modèle global de la Partie 6)**

Nous avons généré quatre figures pour chaque modèle :
- **Courbes ROC/AUC** : Évaluent la capacité des modèles à différencier les classes.
- **Taux de buts vs centile de probabilité** : Indiquent la proportion de buts pour chaque centile de prédiction.
- **Proportion cumulée de buts** : Mesurent la capacité des modèles à capturer les événements les plus importants (buts).
- **Courbes de fiabilité** : Vérifient si les probabilités prédites correspondent aux fréquences observées.

### Résultats pour la saison régulière 2019/20 :

| Modèle         | AUC   |
|----------------|-------|
| Distance Model | 0.682 |
| Angle Model    | 0.511 |
| Combined Model | 0.682 |
| XGBoost        | 0.668 |
| LightGBM       | 0.475 |

Les courbes ci-dessous montrent les performances de chaque modèle.

---

### Distance Model
#### Courbes ROC/AUC
![ROC Distance Model](images/roc_distance_model_Regular_Season.png)

#### Taux de buts vs centile de probabilité
![Goal Rate Distance Model](images/goal_rate_distance_model_Regular_Season.png)

#### Proportion cumulée de buts
![Cumulative Goals Distance Model](images/cumulative_goals_distance_model_Regular_Season.png)

#### Courbe de fiabilité
![Reliability Curve Distance Model](images/calibration_distance_model_Regular_Season.png)

---

### Angle Model
#### Courbes ROC/AUC
![ROC Angle Model](images/roc_angle_model_Regular_Season.png)

#### Taux de buts vs centile de probabilité
![Goal Rate Angle Model](images/goal_rate_angle_model_Regular_Season.png)

#### Proportion cumulée de buts
![Cumulative Goals Angle Model](images/cumulative_goals_angle_model_Regular_Season.png)

#### Courbe de fiabilité
![Reliability Curve Angle Model](images/calibration_angle_model_Regular_Season.png)

---

### Combined Model
#### Courbes ROC/AUC
![ROC Combined Model](images/roc_combined_model_Regular_Season.png)

#### Taux de buts vs centile de probabilité
![Goal Rate Combined Model](images/goal_rate_combined_model_Regular_Season.png)

#### Proportion cumulée de buts
![Cumulative Goals Combined Model](images/cumulative_goals_combined_model_Regular_Season.png)

#### Courbe de fiabilité
![Reliability Curve Combined Model](images/calibration_combined_model_Regular_Season.png)

---

### XGBoost
#### Courbes ROC/AUC
![ROC XGBoost](images/roc_XGBoost_Regular_Season.png)

#### Taux de buts vs centile de probabilité
![Goal Rate XGBoost](images/goal_rate_XGBoost_Regular_Season.png)

#### Proportion cumulée de buts
![Cumulative Goals XGBoost](images/cumulative_goals_XGBoost_Regular_Season.png)

#### Courbe de fiabilité
![Reliability Curve XGBoost](images/calibration_XGBoost_Regular_Season.png)

---

### LightGBM
#### Courbes ROC/AUC
![ROC LightGBM](images/roc_LightGBM_Regular_Season.png)

#### Taux de buts vs centile de probabilité
![Goal Rate LightGBM](images/goal_rate_LightGBM_Regular_Season.png)

#### Proportion cumulée de buts
![Cumulative Goals LightGBM](images/cumulative_goals_LightGBM_Regular_Season.png)

#### Courbe de fiabilité
![Reliability Curve LightGBM](images/calibration_LightGBM_Regular_Season.png)

---

## Discussion des résultats pour la saison régulière :

1. **Performance globale** :
   - Les modèles basés sur la distance et le modèle combiné obtiennent des AUC similaires (0.682), indiquant que l'ajout de l'angle n'offre pas une meilleure performance.
   - Le modèle basé sur l'angle, avec une AUC de 0.511, fonctionne mal. Cela suggère que l'angle seul n'est pas suffisant pour prédire efficacement les buts.
   - Le modèle XGBoost, avec une AUC de 0.668, est légèrement inférieur au modèle combiné mais reste compétitif.
   - LightGBM, avec une AUC de 0.475, montre des performances inférieures, indiquant peut-être un surajustement ou des limitations dans l'ensemble de test.

2. **Généralisation** :
   - Les modèles fonctionnent légèrement moins bien sur l'ensemble de test que sur l'ensemble de validation utilisé lors de leur construction. Cela est attendu et reflète un certain degré de surajustement.
   - Le modèle XGBoost présente une généralisation raisonnable, tandis que LightGBM semble moins performant que prévu.

---

### Évaluation des modèles pour les séries éliminatoires 2019/20

Nous avons également évalué les mêmes cinq modèles sur l'ensemble de données des séries éliminatoires 2019/20. Les résultats sont similaires, mais certaines différences méritent d'être soulignées.

Le modèle **XGBoost** n'a pas été inclus dans cette analyse en raison d'une erreur rencontrée lors du test sur l'ensemble de données des séries éliminatoires.

### Résultats pour les séries éliminatoires 2019/20 :

| Modèle         | AUC   |
|----------------|-------|
| Distance Model | 0.655 |
| Angle Model    | 0.507 |
| Combined Model | 0.655 |
| LightGBM       | 0.493 |

Les courbes ci-dessous montrent les performances des modèles évalués.

---

### Distance Model
#### Courbes ROC/AUC
![ROC Distance Model](images/roc_distance_model_Playoffs.png)

#### Taux de buts vs centile de probabilité
![Goal Rate Distance Model](images/goal_rate_distance_model_Playoffs.png)

#### Proportion cumulée de buts
![Cumulative Goals Distance Model](images/cumulative_goals_distance_model_Playoffs.png)

#### Courbe de fiabilité
![Reliability Curve Distance Model](images/calibration_distance_model_Playoffs.png)

---

### Angle Model
#### Courbes ROC/AUC
![ROC Angle Model](images/roc_angle_model_Playoffs.png)

#### Taux de buts vs centile de probabilité
![Goal Rate Angle Model](images/goal_rate_angle_model_Playoffs.png)

#### Proportion cumulée de buts
![Cumulative Goals Angle Model](images/cumulative_goals_angle_model_Playoffs.png)

#### Courbe de fiabilité
![Reliability Curve Angle Model](images/calibration_angle_model_Playoffs.png)

---

### Combined Model
#### Courbes ROC/AUC
![ROC Combined Model](images/roc_combined_model_Playoffs.png)

#### Taux de buts vs centile de probabilité
![Goal Rate Combined Model](images/goal_rate_combined_model_Playoffs.png)

#### Proportion cumulée de buts
![Cumulative Goals Combined Model](images/cumulative_goals_combined_model_Playoffs.png)

#### Courbe de fiabilité
![Reliability Curve Combined Model](images/calibration_combined_model_Playoffs.png)

---

### LightGBM
#### Courbes ROC/AUC
![ROC LightGBM](images/roc_LightGBM_Playoffs.png)

#### Taux de buts vs centile de probabilité
![Goal Rate LightGBM](images/goal_rate_LightGBM_Playoffs.png)

#### Proportion cumulée de buts
![Cumulative Goals LightGBM](images/cumulative_goals_LightGBM_Playoffs.png)

#### Courbe de fiabilité
![Reliability Curve LightGBM](images/calibration_LightGBM_Playoffs.png)

---

## Discussion des résultats pour les séries éliminatoires :

1. **Performance globale** :
   - Les modèles basés sur la distance et le modèle combiné obtiennent des AUC similaires (0.655), ce qui montre une performance stable par rapport à la saison régulière.
   - Le modèle basé sur l'angle, avec une AUC de 0.507, reste moins performant, confirmant que l'angle seul est une variable moins pertinente.
   - Le modèle LightGBM, avec une AUC de 0.493, montre des performances faibles similaires à celles de la saison régulière.

2. **Exclusion de XGBoost** :
   - Le modèle XGBoost n'a pas été inclus dans cette analyse en raison d'une erreur rencontrée lors du test. Cela souligne l'importance d'un bon traitement des données d'entrée et d'une évaluation robuste.

3. **Comparaison avec la saison régulière** :
   - Les performances globales des modèles montrent une certaine stabilité, bien que l'ensemble de séries éliminatoires soit généralement plus difficile à modéliser en raison de ses spécificités.
