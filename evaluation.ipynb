{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from Modules import plots\n",
    "import xgboost\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"dataframe/test_data_enriched.csv\"  \n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing for xgboost\n",
    "def preprocess_df_xgboost(df):    \n",
    "    numerical_features = ['game_seconds', 'game_period', 'x_coord', 'y_coord', \n",
    "                        'shot_distance', 'shot_angle', 'distance_from_last_event', \n",
    "                        'friendly_skaters', 'opposing_skaters', 'shot_angle_change', 'speed']\n",
    "\n",
    "    categorical_features = [\n",
    "        'shot_type', 'empty_net', 'last_event_type', 'rebound', \n",
    "        'attacking_team_name', 'home_team'\n",
    "    ]\n",
    "\n",
    "    # Handle missing values\n",
    "    df[numerical_features] = df[numerical_features].fillna(df[numerical_features].median())\n",
    "    df[categorical_features] = df[categorical_features].fillna('unknown')\n",
    "\n",
    "    # Encode categorical features using One-Hot Encoding\n",
    "    df_encoded = pd.get_dummies(df[categorical_features], drop_first=True)\n",
    "\n",
    "    # Combine numerical and encoded categorical features\n",
    "    X = pd.concat([df[numerical_features], df_encoded], axis=1)\n",
    "    y = df['is_goal']  \n",
    "    y = y.fillna(0)\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing for lightgbm\n",
    "def preprocess_lightgbm(df):\n",
    "    data_categ = df.select_dtypes(include=['object']).drop(['attacking_team_name', 'home_team'], axis=1, errors='ignore')\n",
    "    data_numer = df.select_dtypes(include=['float64', 'int64']).drop(\n",
    "        ['game_id', 'game_seconds', 'game_period', 'time_since_last_event', 'attacking_team_id'], axis=1, errors='ignore'\n",
    "    )\n",
    "    data_bool = df.select_dtypes(include=['bool'])\n",
    "    le = LabelEncoder()\n",
    "    data_categ = data_categ.apply(le.fit_transform)\n",
    "    df_final = pd.concat([data_categ, data_numer, data_bool], axis=1)\n",
    "    features = [\n",
    "        'speed', 'distance_from_last_event', 'shot_distance', 'shot_angle',\n",
    "        'y_coord', 'last_event_y', 'last_event_x', 'shot_type', 'x_coord',\n",
    "        'shot_angle_change', 'opposing_skaters', 'last_event_type', 'empty_net',\n",
    "        'friendly_skaters', 'rebound'\n",
    "    ]\n",
    "    data_selected = df_final[features]\n",
    "    X = data_selected\n",
    "    y = df['is_goal']\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creation d'une dataframe pour chaque model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of useful columns\n",
    "colonnes_utiles = [\n",
    "    'shot_distance', 'shot_angle', 'is_goal',\n",
    "]\n",
    "\n",
    "# Ensure game_id is a string\n",
    "df['game_id'] = df['game_id'].astype(str)\n",
    "\n",
    "# Filter rows for the regular season\n",
    "regular_df = df[df['game_id'].str[4:6] == '02']\n",
    "playoff_df = df[df['game_id'].str[4:6] == '03'].reset_index(drop=True)\n",
    "\n",
    "# Select only relevant columns for logistic regression\n",
    "regular_logistic = regular_df[colonnes_utiles]\n",
    "playoffs_logistic = playoff_df[colonnes_utiles]\n",
    "\n",
    "X_xgboost_regular,y_xgboost_regular = preprocess_df_xgboost(regular_df)\n",
    "X_xgboost_playoffs,y_xgboost_playoffs = preprocess_df_xgboost(playoff_df)\n",
    "\n",
    "X_lightgbm_regular,y_lightgbm_regular = preprocess_lightgbm(regular_df)\n",
    "X_lightgbm_playoffs,y_lightgbm_playoffs = preprocess_lightgbm(playoff_df)\n",
    "\n",
    "# Feature and target separation for playoffs\n",
    "X_playoff = playoff_df.drop('is_goal', axis=1)\n",
    "y_playoff = playoff_df['is_goal']\n",
    "\n",
    "# Logistic regression features and targets for regular season\n",
    "X_log_regular = regular_logistic.drop('is_goal', axis=1).dropna()\n",
    "y_log_regular = regular_logistic.loc[X_log_regular.index, 'is_goal']\n",
    "\n",
    "# Logistic regression features and targets for playoffs\n",
    "X_log_playoff = playoffs_logistic.drop('is_goal', axis=1).dropna()\n",
    "y_log_playoff = playoffs_logistic.loc[X_log_playoff.index, 'is_goal']\n",
    "\n",
    "\n",
    "# Distance-based features and targets\n",
    "X_distance_regular = regular_df[['shot_distance']]\n",
    "y_distance_regular = regular_df['is_goal']\n",
    "\n",
    "X_distance_playoff = playoff_df[['shot_distance']]\n",
    "y_distance_playoff = playoff_df['is_goal']\n",
    "\n",
    "# Angle-based features and targets\n",
    "X_angle_regular = regular_df[['shot_angle']]\n",
    "y_angle_regular = regular_df['is_goal']\n",
    "\n",
    "X_angle_playoff = playoff_df[['shot_angle']]\n",
    "y_angle_playoff = playoff_df['is_goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\hicha\\OneDrive\\Bureau\\IFT6358\\wandb\\run-20241122_211234-u5yyjlws</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hicham-mazouzi-university-of-montreal/IFT6758.2024-A/runs/u5yyjlws' target=\"_blank\">Test_Evaluation</a></strong> to <a href='https://wandb.ai/hicham-mazouzi-university-of-montreal/IFT6758.2024-A' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hicham-mazouzi-university-of-montreal/IFT6758.2024-A' target=\"_blank\">https://wandb.ai/hicham-mazouzi-university-of-montreal/IFT6758.2024-A</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hicham-mazouzi-university-of-montreal/IFT6758.2024-A/runs/u5yyjlws' target=\"_blank\">https://wandb.ai/hicham-mazouzi-university-of-montreal/IFT6758.2024-A/runs/u5yyjlws</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hicham-mazouzi-university-of-montreal/IFT6758.2024-A/runs/u5yyjlws?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1768b3e4b20>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Wandb project\n",
    "wandb.init(project=\"IFT6758.2024-A\", name=\"Test_Evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download models from wandb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model artifact names\n",
    "model_artifacts = {\n",
    "    \"distance_model\": \"distance_model:v5\",\n",
    "    \"angle_model\": \"angle_model:v5\",\n",
    "    \"combined_model\": \"combined_model:v5\",\n",
    "    \"XGBoost\": \"Best_XGBoost_Q5_2:v0\",\n",
    "    \"LightGBM\": \"lightgbm_model:v1\"  \n",
    "}\n",
    "\n",
    "import os\n",
    "\n",
    "# Load models from Wandb\n",
    "models = {}\n",
    "for model_name, artifact_name in model_artifacts.items():\n",
    "    print(f\"Loading artifact: {artifact_name}...\")\n",
    "    artifact = wandb.use_artifact(artifact_name, type=\"model\")\n",
    "    artifact_dir = artifact.download()\n",
    "    \n",
    "    # List all files in the downloaded directory\n",
    "    downloaded_files = os.listdir(artifact_dir)\n",
    "    print(f\"Files in artifact '{artifact_name}': {downloaded_files}\")\n",
    "    \n",
    "    # Identify and load the relevant model file\n",
    "    if \"XGBoost\" in model_name:\n",
    "        model_file = next((f for f in downloaded_files if f.endswith(\".json\")), None)\n",
    "        if model_file:\n",
    "            model_path = os.path.join(artifact_dir, model_file)\n",
    "            models[model_name] = xgb.Booster()\n",
    "            models[model_name].load_model(model_path)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No .json file found for {model_name}\")\n",
    "    \n",
    "    elif \"LightGBM\" in model_name:\n",
    "        model_file = next((f for f in downloaded_files if f.endswith(\".pkl\")), None)\n",
    "        if model_file:\n",
    "            model_path = os.path.join(artifact_dir, model_file)\n",
    "            with open(model_path, \"rb\") as f:\n",
    "                models[model_name] = pickle.load(f)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No .pkl file found for {model_name}\")\n",
    "    \n",
    "    else:  # Logistic Regression Models\n",
    "        model_file = next((f for f in downloaded_files if f.endswith(\".pkl\")), None)\n",
    "        if model_file:\n",
    "            model_path = os.path.join(artifact_dir, model_file)\n",
    "            with open(model_path, \"rb\") as f:\n",
    "                models[model_name] = pickle.load(f)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No .pkl file found for {model_name}\")\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Models and plot***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation helper function for separate plotting\n",
    "def evaluate_and_generate_separate_plots(models, X_test, y_test, dataset_name):\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name} on {dataset_name}...\")\n",
    "        \n",
    "        # Generate predictions\n",
    "        if isinstance(model, xgb.Booster):\n",
    "            dtest = xgb.DMatrix(X_test)\n",
    "            y_pred_proba = model.predict(dtest)\n",
    "        elif isinstance(model, lgb.Booster):\n",
    "            y_pred_proba = model.predict(X_test, raw_score=False)\n",
    "        else:\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Generate data for plots\n",
    "        roc_data = plots.generate_roc_auc_data(y_test, y_pred_proba)\n",
    "        goal_rate_x, goal_rate_y = plots.generate_goal_rate_data(y_test, y_pred_proba)\n",
    "        cumulative_x, cumulative_y = plots.generate_cumulative_goal_data(y_test, y_pred_proba)\n",
    "        calibration_prob_pred, calibration_prob_true = plots.generate_calibration_data(y_test, y_pred_proba)\n",
    "        \n",
    "        # Generate individual plots\n",
    "        print(f\"Generating plots for {model_name}...\")\n",
    "        \n",
    "        # ROC/AUC Plot\n",
    "        plots.plot_roc_auc([roc_data], [model_name],f\"roc_{model_name}_{dataset_name}.png\")\n",
    "        \n",
    "        # Goal Rate Plot\n",
    "        plots.plot_goal_rate([(goal_rate_x, goal_rate_y)], [model_name],f\"goal_rate_{model_name}_{dataset_name}.png\")\n",
    "        \n",
    "        # Cumulative Goals Plot\n",
    "        plots.plot_cumulative_goals([(cumulative_x, cumulative_y)], [model_name],f\"cumulative_goals_{model_name}_{dataset_name}.png\")\n",
    "        \n",
    "        # Calibration Curve\n",
    "        plots.plot_calibration([y_test], [(calibration_prob_true, calibration_prob_pred)], [model_name],f\"calibration_{model_name}_{dataset_name}.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate a model\n",
    "def evaluate_model(model, X, y, model_name, dataset_name):\n",
    "    \n",
    "    # Predict probabilities for the positive class\n",
    "    y_pred_proba = model.predict_proba(X)[:, 1]   # Extract positive class probabilities\n",
    "\n",
    "    # Generate data for plots using helper functions\n",
    "    roc_data = plots.generate_roc_auc_data(y, y_pred_proba)\n",
    "    goal_rate_x, goal_rate_y = plots.generate_goal_rate_data(y, y_pred_proba)\n",
    "    cumulative_x, cumulative_y = plots.generate_cumulative_goal_data(y, y_pred_proba)\n",
    "    calibration_prob_true, calibration_prob_pred = plots.generate_calibration_data(y, y_pred_proba)\n",
    "\n",
    "    # ROC/AUC Plot\n",
    "    plots.plot_roc_auc([roc_data], [model_name], f\"roc_{model_name}_{dataset_name}.png\")\n",
    "\n",
    "    # Goal Rate Plot\n",
    "    plots.plot_goal_rate([(goal_rate_x, goal_rate_y)], [model_name], f\"goal_rate_{model_name}_{dataset_name}.png\")\n",
    "\n",
    "    # Cumulative Goals Plot\n",
    "    plots.plot_cumulative_goals([(cumulative_x, cumulative_y)], [model_name], f\"cumulative_goals_{model_name}_{dataset_name}.png\")\n",
    "\n",
    "    # Calibration Curve\n",
    "    plots.plot_calibration([y], [y_pred_proba], [model_name], f\"calibration_{model_name}_{dataset_name}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = [\n",
    "    \"last_event_type_period-end\",\n",
    "    \"last_event_type_period-start\",\n",
    "    \"last_event_type_delayed-penalty\",\n",
    "    \"last_event_type_stoppage\",\n",
    "    \"shot_type_unknown\",\n",
    "    \"last_event_type_game-end\"\n",
    "]\n",
    "\n",
    "# Drop the columns from the DataFrame\n",
    "X_xgboost_regular = X_xgboost_regular.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "X_xgboost_playoffs = X_xgboost_playoffs.drop(columns=columns_to_drop, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating distance_model on Regular Season dataset...\n",
      "Shape of y (true labels): (94320,)\n",
      "Shape of calibration_prob_pred (positive class probabilities): (2,)\n",
      "Generating plots for distance_model on Regular Season...\n",
      "Evaluating distance_model on Playoffs dataset...\n",
      "Shape of y (true labels): (9996,)\n",
      "Shape of calibration_prob_pred (positive class probabilities): (2,)\n",
      "Generating plots for distance_model on Playoffs...\n",
      "Evaluating angle_model on Regular Season dataset...\n",
      "Shape of y (true labels): (94320,)\n",
      "Shape of calibration_prob_pred (positive class probabilities): (1,)\n",
      "Generating plots for angle_model on Regular Season...\n",
      "Evaluating angle_model on Playoffs dataset...\n",
      "Shape of y (true labels): (9996,)\n",
      "Shape of calibration_prob_pred (positive class probabilities): (1,)\n",
      "Generating plots for angle_model on Playoffs...\n",
      "Evaluating combined_model on Regular Season dataset...\n",
      "Shape of y (true labels): (94095,)\n",
      "Shape of calibration_prob_pred (positive class probabilities): (2,)\n",
      "Generating plots for combined_model on Regular Season...\n",
      "Evaluating combined_model on Playoffs dataset...\n",
      "Shape of y (true labels): (9961,)\n",
      "Shape of calibration_prob_pred (positive class probabilities): (2,)\n",
      "Generating plots for combined_model on Playoffs...\n",
      "Evaluating XGBoost on Regular Season dataset...\n",
      "y_pred_proba shape: (94320,), y_pred_proba example: [0.02607037 0.0754331  0.02413708 0.00943756 0.24555498]\n",
      "Evaluating LightGBM on Regular Season dataset...\n",
      "Shape of y (true labels): (94320,)\n",
      "Shape of calibration_prob_pred (positive class probabilities): (10,)\n",
      "Generating plots for LightGBM on Regular Season...\n",
      "Evaluating LightGBM on Playoffs dataset...\n",
      "Shape of y (true labels): (9996,)\n",
      "Shape of calibration_prob_pred (positive class probabilities): (10,)\n",
      "Generating plots for LightGBM on Playoffs...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_datasets = [\n",
    "     ('distance_model', X_distance_regular, y_distance_regular, \"Regular Season\"),\n",
    "    ('distance_model', X_distance_playoff, y_distance_playoff, \"Playoffs\"),\n",
    "    ('angle_model', X_angle_regular, y_angle_regular, \"Regular Season\"),\n",
    "    ('angle_model', X_angle_playoff, y_angle_playoff, \"Playoffs\"),\n",
    "    ('combined_model', X_log_regular, y_log_regular, \"Regular Season\"),\n",
    "    ('combined_model', X_log_playoff, y_log_playoff, \"Playoffs\"),\n",
    "    ('XGBoost', X_xgboost_regular, y_xgboost_regular, \"Regular Season\"),\n",
    "    #('XGBoost', X_xgboost_playoffs, y_xgboost_playoffs, \"Playoffs\"),\n",
    "    ('LightGBM', X_lightgbm_regular, y_lightgbm_regular, \"Regular Season\"),\n",
    "    ('LightGBM', X_lightgbm_playoffs, y_lightgbm_playoffs, \"Playoffs\")\n",
    "]\n",
    "\n",
    "for model_name, X, y, dataset_name in model_datasets:\n",
    "    model = models[model_name]  # Retrieve the model from the dictionary\n",
    "\n",
    "    print(f\"Evaluating {model_name} on {dataset_name} dataset...\")\n",
    "\n",
    "    if model_name == 'XGBoost':\n",
    "        # Directly use XGBClassifier's API\n",
    "        dmatrix = xgboost.DMatrix(X) \n",
    "        y_pred_proba = model.predict(dmatrix)  \n",
    "\n",
    "        # Debugging to confirm output\n",
    "        print(f\"y_pred_proba shape: {y_pred_proba.shape}, y_pred_proba example: {y_pred_proba[:5]}\")\n",
    "\n",
    "        # Generate plots\n",
    "        roc_data = plots.generate_roc_auc_data(y, y_pred_proba)\n",
    "        goal_rate_x, goal_rate_y = plots.generate_goal_rate_data(y, y_pred_proba)\n",
    "        cumulative_x, cumulative_y = plots.generate_cumulative_goal_data(y, y_pred_proba)\n",
    "        calibration_prob_pred = y_pred_proba  # Positive class probabilities\n",
    "        calibration_prob_true = y  # True labels\n",
    "\n",
    "        # Plot generation\n",
    "        plots.plot_roc_auc([roc_data], [model_name], f\"roc_{model_name}_{dataset_name}.png\")\n",
    "        plots.plot_goal_rate([(goal_rate_x, goal_rate_y)], [model_name], f\"goal_rate_{model_name}_{dataset_name}.png\")\n",
    "        plots.plot_cumulative_goals([(cumulative_x, cumulative_y)], [model_name], f\"cumulative_goals_{model_name}_{dataset_name}.png\")\n",
    "        plots.plot_calibration([y], [calibration_prob_pred], [model_name], f\"calibration_{model_name}_{dataset_name}.png\")\n",
    "    else:\n",
    "        # Evaluate using the common function for other models\n",
    "        evaluate_model(model, X, y, model_name, dataset_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
